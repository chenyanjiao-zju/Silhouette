## Flintrock --- Spark deploy tool

We can alternatively choose [flintrock](https://github.com/nchammas/flintrock) to fast-deploy the spark cluster.

Running `run_steps.sh` dependency: pip and numpy

download and decompress it and then put dataset to hdfs

- the configure, aws id & key
- launch and wait
- check the Spark Web UI like [pic]()
- install dependency: pip numpy
- download dataset and put into hdfs
= replace the master URL in `run_steps.sh`, mkdir result
- run `run_steps.sh` and monitor in Web UI
- process the data

- or install scikit-learn


for terasort
